{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import urllib\n",
    "import time\n",
    "import sys\n",
    "import datetime\n",
    "import random\n",
    "from collections import Counter\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "from unidecode import unidecode\n",
    "from webdriver_manager.firefox import GeckoDriverManager\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "from selenium.webdriver.firefox.options import Options\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.common.exceptions import NoSuchElementException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_driver(url):\n",
    "    \"\"\"\n",
    "    Given a URL string, opens the URL in a headless Firefox instance. \n",
    "    \n",
    "    Returns a reference to the webdriver object\n",
    "    \"\"\"\n",
    "    \n",
    "    buttons = []\n",
    "    driver_options = Options()\n",
    "#     driver_options.headless = True\n",
    "    \n",
    "    print(\"\\n\\n*****\" + str(datetime.datetime.now()) + \"*****\")\n",
    "    \n",
    "    driver = webdriver.Firefox(options=driver_options, executable_path=GeckoDriverManager().install())\n",
    "    \n",
    "    # WARNING, THIS IS SPECIFIC TO THIS MACHINE (retrieves the installed uBlock Origin from the Firefox on this computer.) Need a computer-agnostic way.\n",
    "    driver.install_addon(\"~/.mozilla/firefox/f4t6w0s5.default-release/extensions/uBlock0@raymondhill.net.xpi\", temporary=True)\n",
    "\n",
    "#     driver.get(url)\n",
    "    \n",
    "    time.sleep(.5)\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def compare_tokens(tokens1, tokens2):\n",
    "#     \"\"\"Compares two lists of string tokens for equality as used in soup_it.\"\"\"\n",
    "    \n",
    "#     # Iterates through each token\n",
    "#     for index in range(len(tokens1)):\n",
    "#         # \n",
    "#         if index >= len(tokens2):\n",
    "#             return False\n",
    "    \n",
    "#         comparison1 = tokens1[index]\n",
    "        \n",
    "        \n",
    "#         comparison2 = tokens2[index]\n",
    "        \n",
    "#         # Case of initials\n",
    "#         if \".\" in tokens1[index] or \".\" in tokens2:\n",
    "            \n",
    "#     return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def click_and_wait(driver, element, find_elements_by):\n",
    "    \"\"\" \n",
    "    Clicks on element and waits for a page load. \n",
    "    \n",
    "    Parameters:\n",
    "    driver == webdriver\n",
    "    element == string to find (class or css_selector)\n",
    "    find_elements_by == integer: 0 for css_selector, 1 for class_name.\n",
    "    \n",
    "    Only works on an actual page load (will hang if the click only runs dynamic JS on the same webpage)\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        if find_elements_by == 0:\n",
    "            button = driver.find_element_by_css_selector(element)\n",
    "        else:\n",
    "            button = driver.find_element_by_class_name(element)\n",
    "            \n",
    "        driver.execute_script(\"arguments[0].click()\", button)\n",
    "    except:\n",
    "        print(\"No button\")\n",
    "        \n",
    "    old_driver = driver.find_element_by_tag_name('html')\n",
    "\n",
    "    WebDriverWait(driver, 10).until(EC.staleness_of(old_driver))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def search_paper(doi, driver):\n",
    "#     \"\"\"\n",
    "#     Given a DOI and a given driver (on search) page, searches the DOI to open up the paper in the page. \n",
    "    \n",
    "#     Returns the webdriver associated with it.\n",
    "#     \"\"\"\n",
    "\n",
    "#     if \"www.researchgate.net/search\" in driver.current_url:\n",
    "#         search_input = \"search-form__input\"\n",
    "#         search_button = \"search-form__left-button\"\n",
    "#     else:\n",
    "#         search_input = \"lite-page__header-search-input\"\n",
    "#         search_button = \"lite-page__header-search-button\"\n",
    "    \n",
    "#     print(\"\\n---\" + \"New search \" + str(datetime.datetime.now()) + \"---\")\n",
    "#     print(\"DOI: \" + doi)\n",
    "    \n",
    "    \n",
    "#     search_field_list = driver.find_element_by_class_name(search_input)\n",
    "#     time.sleep(.25) # added for stability\n",
    "#     search_field = search_field_list\n",
    "#     time.sleep(.25)\n",
    "#     search_field.clear()\n",
    "#     time.sleep(.25)\n",
    "#     search_field.send_keys(doi)\n",
    "    \n",
    "#     enter_field = driver.find_element_by_class_name(search_button)\n",
    "#     driver.execute_script(\"arguments[0].click()\", enter_field)\n",
    "    \n",
    "#     old_driver = driver.find_element_by_tag_name('html')\n",
    "#     WebDriverWait(driver, 10).until(EC.staleness_of(old_driver))\n",
    "  \n",
    "#     click_and_wait(driver, \"a[href*='search/data']\", 0)\n",
    "    \n",
    "#     if \"www.researchgate.net/search\" in driver.current_url:\n",
    "#         print(\"Paper not found (search)\")\n",
    "#         return None\n",
    "#     else: \n",
    "#         print(\"Success\")\n",
    "#         return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_paper(doi, driver, engine):\n",
    "    \"\"\"\n",
    "    Given a DOI, an existing driver, and an engine number (0 for Google, 1 for DDG), search for paper.\n",
    "    \n",
    "    Returns the associated webdriver.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\n---\" + \"New search \" + str(datetime.datetime.now()) + \"---\")\n",
    "    print(\"DOI: \" + doi)\n",
    "    \n",
    "    if engine == 0:\n",
    "        search_engine = \"https://www.google.com\"\n",
    "        # Constructs the string being searched, randomizes it so it's not so robotic\n",
    "        if random.randint(0, 1) == 0:\n",
    "            query_string = '\"' + doi + '\"' + ' ' + '\"researchgate.net\"'\n",
    "        else:\n",
    "            query_string = '\"researchgate.net\"' + ' ' + '\"' + doi + '\"'\n",
    "        query_string + \" -filetype:pdf\"\n",
    "            \n",
    "    elif engine == 1:\n",
    "        search_engine = \"https://duckduckgo.com/\"\n",
    "        query_string = '\\\\research gate' + ' ' + '\"' + doi + '\"'\n",
    "    \n",
    "    driver.get(search_engine)\n",
    "\n",
    "    \n",
    "    # Enters search string into searchbox\n",
    "    if engine == 0:\n",
    "        try: \n",
    "            blah = driver.find_element_by_xpath(\"/html/body/div/div[3]/form/div[2]/div/div[1]/div/div[1]/input\")\n",
    "        except NoSuchElementException: # Tries div[2]\n",
    "            print(\"Trying second xpath\")\n",
    "            blah = driver.find_element_by_xpath(\"/html/body/div/div[3]/form/div[2]/div/div[1]/div/div[2]/input\")\n",
    "        \n",
    "    \n",
    "    elif engine == 1:\n",
    "        blah = driver.find_element_by_xpath('//*[@id=\"search_form_input_homepage\"]')\n",
    "        \n",
    "    blah.send_keys(query_string)\n",
    "    \n",
    "    \n",
    "    time.sleep(random.randint(2, 7)) # to respect crawling\n",
    "    \n",
    "    if engine == 0:\n",
    "        # Clicks on \"I'm Feeling Lucky\" button\n",
    "        button = driver.find_element_by_xpath('//*[@id=\"gbqfbb\"]')\n",
    "        driver.execute_script(\"arguments[0].click()\", button)\n",
    "    elif engine == 1:\n",
    "        blah.send_keys(Keys.RETURN)\n",
    "\n",
    "    # Waits for page to load\n",
    "    old_driver = driver.find_element_by_tag_name('html')\n",
    "    WebDriverWait(driver, 10).until(EC.staleness_of(old_driver))\n",
    "    time.sleep(2) # increased from .5 to 2 to respect crawling\n",
    "    \n",
    "    # Checks if paper was found\n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    if \"/sorry/\" in driver.current_url:\n",
    "        raise Exception(\"Captcha'd\")\n",
    "        \n",
    "        return None\n",
    "    elif \"google.com\" in driver.current_url:\n",
    "        print(\"Paper not found\")\n",
    "        return None\n",
    "    else:\n",
    "        # Prints DOI string. Need to compare it to the actual doi to see if it's the correct paper.\n",
    "        print(\"Success: found at \" + str(driver.current_url))\n",
    "        return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_authors(driver): \n",
    "    \"\"\"\n",
    "    Given the webdriver, shows more authors. \n",
    "    \n",
    "    Returns the modified webdriver.\n",
    "    \"\"\"\n",
    "    \n",
    "    if not driver:\n",
    "        print(\"Exiting: No driver\")\n",
    "        return None\n",
    "    \n",
    "    first_start = time.time()\n",
    "    \n",
    "    time.sleep(2) # Increase from .5 to 2 for stability\n",
    "    \n",
    "    try:\n",
    "        button = driver.find_element_by_xpath(\"/html/body/div[2]/main/section/section[1]/div[2]/a\")\n",
    "        driver.execute_script(\"arguments[0].click()\", button)\n",
    "    except:\n",
    "        print(\"No button\")\n",
    "    \n",
    "    first_end = time.time()\n",
    "\n",
    "    print(\"DONE - \" + str(first_end-first_start))\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_chars(string):\n",
    "    \"\"\"Removes - and space characters from a string\"\"\"\n",
    "    \n",
    "    return string.translate({ord(char): None for char in \"- \"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def common_chars(string1, string2):\n",
    "    \"\"\"Counts the number of common characters in two strings\"\"\"\n",
    "    \n",
    "    common = Counter(string1.casefold()) & Counter(string2.casefold())\n",
    "    return sum(common.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_names(query_name, rg_name):\n",
    "    \"\"\"Compare names while agnostic to special characters and rearranged names\"\"\"\n",
    "    \n",
    "    # If one string is empty and not the other, return false\n",
    "    if (query_name == \"\" and rg_name != \"\") or (query_name != \"\" and rg_name == \"\"):\n",
    "        return False\n",
    "    \n",
    "    # Removes spaces and - from names\n",
    "    query_clean = remove_chars(query_name)\n",
    "    rg_clean = remove_chars(rg_name)\n",
    "    \n",
    "    # Same length and same amount of common characters\n",
    "    return len(query_clean) <= len(rg_clean) and common_chars(query_clean, rg_clean) == len(query_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_check(name):\n",
    "    \"\"\"Checks if name is an initial, returns true if so\"\"\"\n",
    "    \n",
    "    return (len(name) == 1) or (\".\" in name)\n",
    "# len(name) == 2 and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_authors(query_author, rg_author):\n",
    "    \"\"\"\n",
    "    Compares authors\n",
    "    \n",
    "    Parameters:\n",
    "    query_author : list of of queried author's first name then last name\n",
    "    rg_author    : string of researchgate author's full name\n",
    "    \"\"\"\n",
    "    \n",
    "    # Checks if rg_author has any special non-ASCII characters. Translates query_author based on that and sets the author's first and last name strings.\n",
    "    # Still doesn't address if one half of name uses UTF-8 only characters and the other half doesn't) but unlikely case\n",
    "    if unidecode(rg_author) == rg_author:\n",
    "        author_first = unidecode(query_author[0]).split()\n",
    "        author_last = unidecode(query_author[2]).split()\n",
    "    else:\n",
    "        author_first = query_author[0].split()\n",
    "        author_last = query_author[2].split()\n",
    "    \n",
    "    # Splits rg_author into tokens\n",
    "    rg_tokens = rg_author.split()\n",
    "    \n",
    "    # Removes Jr from last name. Need to put the last check in case someone is just named \"Jr\"\n",
    "    if len(rg_tokens) > 1 and rg_tokens[-1] == \"Jr\" or rg_tokens[-1] == \"Jr.\":\n",
    "        rg_tokens.pop(-1)\n",
    "    \n",
    "    # Deals with no first_name in query_author\n",
    "    if author_first == \"\" and compare_names(author_last, rg_tokens[-1]):\n",
    "        return True\n",
    "        \n",
    "    # Incase rg_author uses first name initial, compares the first letter of queried author's first name to that string\n",
    "    if initial_check(rg_tokens[0]):\n",
    "        author_first[0] = str(author_first[0][0]) + \".\"\n",
    "    \n",
    "    # Merges first name for queried author\n",
    "    merged_author_first = \"\"\n",
    "    for name in author_first:\n",
    "        \n",
    "        # Incase rg_author uses first name initial, compares the first letter of queried author's first name to that string\n",
    "        if initial_check(rg_tokens[0]):\n",
    "            name = name[0] + \".\"\n",
    "           \n",
    "        merged_author_first = merged_author_first + name\n",
    "        \n",
    "    # Assigns last name to last part of last name\n",
    "    author_last = author_last[-1]\n",
    "    \n",
    "    # Merges all but last name for researchgate name\n",
    "    merged_rg_first = \"\"\n",
    "    for name in rg_tokens[:-1]:\n",
    "        \n",
    "        # Adds periods to initials in the name\n",
    "        if len(name) == 1:\n",
    "            name = name + \".\"\n",
    "        \n",
    "        # Converts name to initial of queried author is in initial\n",
    "        if initial_check(author_first[0]):\n",
    "            name = name[0] + \".\"\n",
    "        \n",
    "        merged_rg_first = merged_rg_first + name\n",
    "        \n",
    "    return ( compare_names(merged_author_first, merged_rg_first) and author_last.casefold() == rg_tokens[-1].casefold() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def soup_it(driver, author_tokens, pairing_dict, author_id):\n",
    "    \"\"\"\n",
    "    Given the webdriver, parses its source for author URLs.\n",
    "    \n",
    "    Parameters:\n",
    "    driver == webdriver\n",
    "    author_tokens == list containing the searched author's name in tokens delimited by spaces\n",
    "    pairing_dict == Dictionary to store the URLs into (for the respective author indicated by author_id)\n",
    "    author_id == The searched author's id for usage in pairing_dict \n",
    "    \"\"\"    \n",
    "    \n",
    "    time.sleep(.5) # Increased to .5 for stability\n",
    "      \n",
    "    if driver is None:\n",
    "        print(\"No soup for you\")\n",
    "        pairing_dict[author_id] = \"NO_PAPER\"\n",
    "        return -1\n",
    "    \n",
    "    success = 0\n",
    "    \n",
    "    soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    thing = soup.find_all('div', {\"class\": \"nova-v-person-list-item__title\"})\n",
    "    \n",
    "    print(\"Searching for: \" + str(author_tokens))\n",
    "    \n",
    "    for stuff in thing:     \n",
    "        author_name = stuff.find('a').string\n",
    "        author_url = stuff.find('a').get(\"href\")\n",
    "        \n",
    "#         # Checks first name on researchgate is initial (e.g. if author only has a \"scientific-contributions\" page), if so then compare first initials\n",
    "#         if \".\" in author_name.split()[0] or len(author_name.split()[0]) == 1:\n",
    "#             author_first[0] = str(author_first[0][0]) + \".\"\n",
    "                \n",
    "#         print(str(author_first) + \" \" + str(author_last) + \" and \" + author_name)\n",
    "        \n",
    "#         # Full name\n",
    "#         if len(author_first[0]) >= 2 and \".\" not in author_first[0] and author_first[0].casefold() == author_name.split()[0].casefold() \\\n",
    "#             and author_last[-1].casefold() == author_name.split()[-1].casefold():\n",
    "            \n",
    "#             print(str(author_url) + \" <-------------\")\n",
    "#             pairing_dict[author_id] = author_url\n",
    "            \n",
    "#             success = 1\n",
    "            \n",
    "#         # First initial\n",
    "#         elif ( (len(author_first[0]) == 2 and \".\" in author_first[0]) or (len(author_tokens[0]) == 1) ) \\\n",
    "#             and author_first[0][0].casefold() in author_name.split()[0][0].casefold() \\\n",
    "#             and author_last[-1].casefold() == author_name.split()[-1].casefold():\n",
    "            \n",
    "#             print(str(author_url) + \" <-------------\")\n",
    "#             pairing_dict[author_id] = author_url\n",
    "            \n",
    "#             success = 1\n",
    "            \n",
    "#         # No first name\n",
    "#         elif author_first[0] == \"\" and author_last[-1].casefold() == author_name.split()[-1].casefold():\n",
    "#             print(str(author_url) + \" <-------------\")\n",
    "#             pairing_dict[author_id] = author_url\n",
    "            \n",
    "#             success = 1\n",
    "        if compare_authors(author_tokens, author_name):\n",
    "            print(str(author_url) + \" <---------------- \" + author_name)\n",
    "            pairing_dict[author_id] = author_url\n",
    "            success = 1\n",
    "        else:\n",
    "            print(author_url + \" ~ \" + author_name)\n",
    "\n",
    "    if success == 0:\n",
    "        pairing_dict[author_id] = \"NOT_FOUND\"\n",
    "        \n",
    "    return success"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_file_descriptor = sys.stdout\n",
    "sys.stdout = open(\"./scraping_log.txt\", \"a\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./stored_authors/authors_and_papers.txt\", encoding=\"utf8\") as papers_file:\n",
    "    authors_and_papers = eval(papers_file.read())\n",
    "with open(\"./stored_authors/authors_ids.txt\", encoding=\"utf8\") as authors_file:\n",
    "    authors_ids = eval(authors_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# authors_urls = {}\n",
    "\n",
    "# for author in authors_and_papers:\n",
    "#     authors_urls[author] = None\n",
    "\n",
    "with open(\"./stored_authors/author_url_pairings.txt\", encoding=\"utf8\") as author_pair_file:\n",
    "    authors_urls = eval(author_pair_file.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchWindowException",
     "evalue": "Message: Browsing context has been discarded\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNoSuchWindowException\u001b[0m                     Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-99-ec5286cb8339>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0msuccess\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoup_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshow_authors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msearch_paper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthors_and_papers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthors_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthors_urls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mauthor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m             \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-40-f5e26bf00893>\u001b[0m in \u001b[0;36msearch_paper\u001b[0;34m(doi, driver, engine)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;31m# Checks if paper was found\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0msoup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_source\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html.parser'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"/sorry/\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_url\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Captcha'd\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mcurrent_url\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    667\u001b[0m             \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_url\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    668\u001b[0m         \"\"\"\n\u001b[0;32m--> 669\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCommand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGET_CURRENT_URL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'value'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    671\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/selenium/webdriver/remote/webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self, driver_command, params)\u001b[0m\n\u001b[1;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 321\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[1;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[0;32m~/.local/lib/python3.7/site-packages/selenium/webdriver/remote/errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[0;34m(self, response)\u001b[0m\n\u001b[1;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'alert'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 242\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    243\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNoSuchWindowException\u001b[0m: Message: Browsing context has been discarded\n"
     ]
    }
   ],
   "source": [
    "search_engine = \"https://www.google.com\"  # i.e. 0\n",
    "# search_engine = \"https://duckduckgo.com/\" # i.e. 1\n",
    "\n",
    "if search_engine == \"https://www.google.com\":\n",
    "    engine_number = 0\n",
    "elif search_engine == \"https://duckduckgo.com/\":\n",
    "    engine_number = 1\n",
    "\n",
    "driver = obtain_driver(search_engine)\n",
    "time.sleep(2)\n",
    "\n",
    "for author in authors_urls:\n",
    "    if authors_urls[author] == None:\n",
    "        \n",
    "        # Author has no associated paper\n",
    "        if len(authors_and_papers[author]) == 0:\n",
    "            print(\"\\n\\nAUTHOR HAS NO PAPER\")\n",
    "            authors_urls[author] = \"AUTHOR_HAS_NO_PAPER\"\n",
    "            \n",
    "            driver.quit()\n",
    "            time.sleep(1)\n",
    "            driver = obtain_driver(search_engine)\n",
    "            time.sleep(2)\n",
    "            \n",
    "        else:\n",
    "            success = soup_it(show_authors(search_paper(authors_and_papers[author][0], driver, engine_number)), authors_ids[author], authors_urls, author)\n",
    "            print(author)\n",
    "            sys.stdout.flush()\n",
    "\n",
    "            if success == -1 or success == 0:\n",
    "                driver.quit()\n",
    "                time.sleep(1)\n",
    "                driver = obtain_driver(search_engine)\n",
    "                time.sleep(2)\n",
    "\n",
    "        time.sleep(random.randint(6, 12)) # Increased from 1 to 6-12 to respect crawling\n",
    "        \n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./stored_authors/author_url_pairings.txt\", \"w\") as dup_file:\n",
    "    pprint(authors_urls, stream = dup_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.stdout = original_file_descriptor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "997\n"
     ]
    }
   ],
   "source": [
    "print(len(authors_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****2019-06-25 16:10:43.533727*****\n",
      "\n",
      "Checking for linux64 geckodriver:v0.24.0 in cache\n",
      "Driver found in /home/local/NIST/jfl2/.wdm/geckodriver/v0.24.0/linux64/geckodriver\n",
      "\n",
      "---New search 2019-06-25 16:10:56.303352---\n",
      "DOI: 10.1016/j.coal.2013.11.009\n",
      "Success\n",
      "No button\n",
      "DONE - 0.5094668865203857\n",
      "['Khaled', 'A.'] ['Gasem'] and Pongtorn Chareonsuppanimit\n",
      "https://www.researchgate.net/profile/Pongtorn_Chareonsuppanimit\n",
      "['Khaled', 'A.'] ['Gasem'] and Sayeed A. Mohammad\n",
      "https://www.researchgate.net/scientific-contributions/85514326_Sayeed_A_Mohammad\n",
      "['Khaled', 'A.'] ['Gasem'] and Robert L. Robinson Jr\n",
      "https://www.researchgate.net/profile/Robert_Jr2\n",
      "['Khaled', 'A.'] ['Gasem'] and Khaled Gasem\n",
      "https://www.researchgate.net/profile/Khaled_Gasem <-------------\n"
     ]
    }
   ],
   "source": [
    "# Testing Khaled (multiple words in first name)\n",
    "\n",
    "driver = obtain_driver(\"https://www.researchgate.net/search\")\n",
    "time.sleep(2)\n",
    "\n",
    "author = \"1d13bd887854f23bc64bab2b7d388d0bbcd1b333\"\n",
    "\n",
    "soup_it(show_authors(search_paper(\"10.1016/j.coal.2013.11.009\", driver)), authors_ids[author], authors_urls, author)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****2019-06-25 14:13:52.063208*****\n",
      "\n",
      "Checking for linux64 geckodriver:v0.24.0 in cache\n",
      "Driver found in /home/local/NIST/jfl2/.wdm/geckodriver/v0.24.0/linux64/geckodriver\n",
      "\n",
      "---New search 2019-06-25 14:14:04.935616---\n",
      "DOI: 10.1007/s10450-018-9958-x\n",
      "Success\n",
      "DONE - 0.543921947479248\n",
      "['M'] ['Hudson'] and Huong Giang Nguyen\n",
      "https://www.researchgate.net/profile/Huong_Giang_Nguyen\n",
      "['M'] ['Hudson'] and Laura Espinal\n",
      "https://www.researchgate.net/profile/Laura_Espinal\n",
      "['M.'] ['Hudson'] and R. D. van Zee\n",
      "https://www.researchgate.net/scientific-contributions/2133349107_R_D_van_Zee\n",
      "['M.'] ['Hudson'] and M. Thommes\n",
      "https://www.researchgate.net/scientific-contributions/11437659_M_Thommes\n",
      "['M'] ['Hudson'] and Blaza Toman\n",
      "https://www.researchgate.net/profile/Blaza_Toman\n",
      "['M.'] ['Hudson'] and M. Sterlin Leo Hudson\n",
      "https://www.researchgate.net/profile/M_Sterlin_Hudson <-------------\n",
      "['M'] ['Hudson'] and Enzo Mangano\n",
      "https://www.researchgate.net/profile/Enzo_Mangano\n",
      "['M'] ['Hudson'] and Stefano Brandani\n",
      "https://www.researchgate.net/profile/Stefano_Brandani\n",
      "['M'] ['Hudson'] and Darren Paul Broom\n",
      "https://www.researchgate.net/profile/Darren_Broom\n",
      "['M.'] ['Hudson'] and M. J. Benham\n",
      "https://www.researchgate.net/scientific-contributions/2145380044_M_J_Benham\n",
      "['M.'] ['Hudson'] and K. Cychosz\n",
      "https://www.researchgate.net/scientific-contributions/57866576_K_Cychosz\n",
      "['M'] ['Hudson'] and Pieter Bertier\n",
      "https://www.researchgate.net/profile/Pieter_Bertier\n",
      "['M'] ['Hudson'] and Feng Yang\n",
      "https://www.researchgate.net/profile/Feng_Yang46\n",
      "['M'] ['Hudson'] and Bernhard Martin Krooss\n",
      "https://www.researchgate.net/profile/Bernhard_Krooss\n",
      "['M.'] ['Hudson'] and R. L. Siegelman\n",
      "https://www.researchgate.net/scientific-contributions/2096360797_R_L_Siegelman\n",
      "['M.'] ['Hudson'] and M. Hakuman\n",
      "https://www.researchgate.net/scientific-contributions/2145401361_M_Hakuman\n",
      "['M.'] ['Hudson'] and K. Nakai\n",
      "https://www.researchgate.net/scientific-contributions/2145386838_K_Nakai\n",
      "['M.'] ['Hudson'] and A. D. Ebner\n",
      "https://www.researchgate.net/scientific-contributions/2145390013_A_D_Ebner\n",
      "['M'] ['Hudson'] and Lutfi Erden\n",
      "https://www.researchgate.net/profile/Lutfi_Erden\n",
      "['M.'] ['Hudson'] and J. A. Ritter\n",
      "https://www.researchgate.net/scientific-contributions/2145401773_J_A_Ritter\n",
      "['M.'] ['Hudson'] and A. Moran\n",
      "https://www.researchgate.net/scientific-contributions/2145374179_A_Moran\n",
      "['M.'] ['Hudson'] and O. Talu\n",
      "https://www.researchgate.net/scientific-contributions/2145398477_O_Talu\n",
      "['M'] ['Hudson'] and Yi Huang\n",
      "https://www.researchgate.net/profile/Yi_Huang131\n",
      "['M.'] ['Hudson'] and K. S. Walton\n",
      "https://www.researchgate.net/scientific-contributions/2145401594_K_S_Walton\n",
      "['M'] ['Hudson'] and Pierre Billemont\n",
      "https://www.researchgate.net/profile/Pierre_Billemont\n",
      "['M'] ['Hudson'] and Guy De Weireld\n",
      "https://www.researchgate.net/profile/Guy_De_Weireld\n"
     ]
    }
   ],
   "source": [
    "# Testing M Hudson\n",
    "\n",
    "driver = obtain_driver(\"https://www.researchgate.net/search\")\n",
    "time.sleep(2)\n",
    "\n",
    "author = \"0000-0001-8155-6489\"\n",
    "\n",
    "soup_it(show_authors(search_paper(\"10.1007/s10450-018-9958-x\", driver)), authors_ids[author], authors_urls, author)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****2019-06-25 13:08:05.523798*****\n",
      "\n",
      "Checking for linux64 geckodriver:v0.24.0 in cache\n",
      "Driver found in /home/local/NIST/jfl2/.wdm/geckodriver/v0.24.0/linux64/geckodriver\n",
      "\n",
      "---New search 2019-06-25 13:08:17.251158---\n",
      "DOI: 10.1016/j.cplett.2011.11.054\n",
      "Success\n",
      "No button\n",
      "DONE - 0.012266874313354492\n",
      "['Carlos'] ['Otero', 'Areán'] and Carlos Otero Areán\n",
      "https://www.researchgate.net/profile/Carlos_Arean <-------------\n",
      "['Carlos'] ['Otero', 'Arean'] and Carlos Palomino Cabello\n",
      "https://www.researchgate.net/profile/Carlos_Palomino_Cabello\n",
      "['Carlos'] ['Otero', 'Arean'] and Gemma Turnes Palomino\n",
      "https://www.researchgate.net/profile/Gemma_Turnes_Palomino\n"
     ]
    }
   ],
   "source": [
    "# Testing Carlos Otero Arean (last name is two names)\n",
    "\n",
    "driver = obtain_driver(\"https://www.researchgate.net/search\")\n",
    "time.sleep(1)\n",
    "\n",
    "author = \"0000-0002-2980-7997\"\n",
    "\n",
    "soup_it(show_authors(search_paper(\"10.1016/j.cplett.2011.11.054\", driver)), authors_ids[author], authors_urls, author)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****2019-06-25 13:09:56.553568*****\n",
      "\n",
      "Checking for linux64 geckodriver:v0.24.0 in cache\n",
      "Driver found in /home/local/NIST/jfl2/.wdm/geckodriver/v0.24.0/linux64/geckodriver\n",
      "\n",
      "---New search 2019-06-25 13:10:08.107685---\n",
      "DOI: 10.1039/C4TA05225K \n",
      "Success\n",
      "DONE - 0.05252337455749512\n",
      "['Tao'] ['Li'] and surendar reddy Venna\n",
      "https://www.researchgate.net/profile/Surendar_reddy_Venna\n",
      "['Tao'] ['Li'] and Michael Lartey\n",
      "https://www.researchgate.net/profile/Michael_Lartey6\n",
      "['Tao'] ['Li'] and Tao li\n",
      "https://www.researchgate.net/profile/Tao_Li73 <-------------\n",
      "['Tao'] ['Li'] and Alex Spore\n",
      "https://www.researchgate.net/scientific-contributions/2065445495_Alex_Spore\n",
      "['Tao'] ['Li'] and Santosh Kumar\n",
      "https://www.researchgate.net/scientific-contributions/2065452147_Santosh_Kumar\n",
      "['Tao'] ['Li'] and Hunaid B. Nulwala\n",
      "https://www.researchgate.net/profile/Hunaid_Nulwala\n",
      "['Tao'] ['Li'] and David Richard Luebke\n",
      "https://www.researchgate.net/scientific-contributions/2007995838_David_Richard_Luebke\n",
      "['Tao'] ['Li'] and Nathaniel L. Rosi\n",
      "https://www.researchgate.net/scientific-contributions/2052399408_Nathaniel_L_Rosi\n",
      "['Tao'] ['Li'] and Erik Albenze\n",
      "https://www.researchgate.net/scientific-contributions/2006177688_Erik_Albenze\n"
     ]
    }
   ],
   "source": [
    "# Testing Tao li (case matching)\n",
    "\n",
    "driver = obtain_driver(\"https://www.researchgate.net/search\")\n",
    "time.sleep(1)\n",
    "\n",
    "author = \"fb51c9b3b4998ec6cca5977372fc110212d1a8c6\"\n",
    "\n",
    "soup_it(show_authors(search_paper(\"10.1039/C4TA05225K \", driver)), authors_ids[author], authors_urls, author)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****2019-06-25 13:11:08.667032*****\n",
      "\n",
      "Checking for linux64 geckodriver:v0.24.0 in cache\n",
      "Driver found in /home/local/NIST/jfl2/.wdm/geckodriver/v0.24.0/linux64/geckodriver\n",
      "\n",
      "---New search 2019-06-25 13:11:20.819320---\n",
      "DOI: 10.1021/ic201596x \n",
      "Success\n",
      "No button\n",
      "DONE - 0.006753444671630859\n",
      "['Michael'] ['Froba'] and Daniela Frahm\n",
      "https://www.researchgate.net/scientific-contributions/58927593_Daniela_Frahm\n",
      "['Michael'] ['Froba'] and Michael Fischer\n",
      "https://www.researchgate.net/profile/Michael_Fischer3\n",
      "['Michael'] ['Froba'] and Frank Hoffmann\n",
      "https://www.researchgate.net/profile/Frank_Hoffmann2\n",
      "['Michael'] ['Fröba'] and Michael Fröba\n",
      "https://www.researchgate.net/profile/Michael_Froeba <-------------\n"
     ]
    }
   ],
   "source": [
    "# Testing Froeba (matching special characters)\n",
    "\n",
    "driver = obtain_driver(\"https://www.researchgate.net/search\")\n",
    "time.sleep(1)\n",
    "\n",
    "author = \"13a7a901aac8693e7b652cdf66ec4eeeace36f3f\"\n",
    "\n",
    "soup_it(show_authors(search_paper(\"10.1021/ic201596x \", driver)), authors_ids[author], authors_urls, author)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****2019-06-25 13:11:34.401229*****\n",
      "\n",
      "Checking for linux64 geckodriver:v0.24.0 in cache\n",
      "Driver found in /home/local/NIST/jfl2/.wdm/geckodriver/v0.24.0/linux64/geckodriver\n",
      "\n",
      "---New search 2019-06-25 13:11:45.878041---\n",
      "DOI: 10.1007/s10450-018-9958-x\n",
      "Success\n",
      "DONE - 0.18370318412780762\n",
      "['Rebecca'] ['Siegelman'] and Huong Giang Nguyen\n",
      "https://www.researchgate.net/profile/Huong_Giang_Nguyen\n",
      "['Rebecca'] ['Siegelman'] and Laura Espinal\n",
      "https://www.researchgate.net/profile/Laura_Espinal\n",
      "['R.'] ['Siegelman'] and R. D. van Zee\n",
      "https://www.researchgate.net/scientific-contributions/2133349107_R_D_van_Zee\n",
      "['R.'] ['Siegelman'] and M. Thommes\n",
      "https://www.researchgate.net/scientific-contributions/11437659_M_Thommes\n",
      "['Rebecca'] ['Siegelman'] and Blaza Toman\n",
      "https://www.researchgate.net/profile/Blaza_Toman\n",
      "['R.'] ['Siegelman'] and M. Sterlin Leo Hudson\n",
      "https://www.researchgate.net/profile/M_Sterlin_Hudson\n",
      "['Rebecca'] ['Siegelman'] and Enzo Mangano\n",
      "https://www.researchgate.net/profile/Enzo_Mangano\n",
      "['Rebecca'] ['Siegelman'] and Stefano Brandani\n",
      "https://www.researchgate.net/profile/Stefano_Brandani\n",
      "['Rebecca'] ['Siegelman'] and Darren Paul Broom\n",
      "https://www.researchgate.net/profile/Darren_Broom\n",
      "['R.'] ['Siegelman'] and M. J. Benham\n",
      "https://www.researchgate.net/scientific-contributions/2145380044_M_J_Benham\n",
      "['R.'] ['Siegelman'] and K. Cychosz\n",
      "https://www.researchgate.net/scientific-contributions/57866576_K_Cychosz\n",
      "['Rebecca'] ['Siegelman'] and Pieter Bertier\n",
      "https://www.researchgate.net/profile/Pieter_Bertier\n",
      "['Rebecca'] ['Siegelman'] and Feng Yang\n",
      "https://www.researchgate.net/profile/Feng_Yang46\n",
      "['Rebecca'] ['Siegelman'] and Bernhard Martin Krooss\n",
      "https://www.researchgate.net/profile/Bernhard_Krooss\n",
      "['R.'] ['Siegelman'] and R. L. Siegelman\n",
      "https://www.researchgate.net/scientific-contributions/2096360797_R_L_Siegelman <-------------\n",
      "['R.'] ['Siegelman'] and M. Hakuman\n",
      "https://www.researchgate.net/scientific-contributions/2145401361_M_Hakuman\n",
      "['R.'] ['Siegelman'] and K. Nakai\n",
      "https://www.researchgate.net/scientific-contributions/2145386838_K_Nakai\n",
      "['R.'] ['Siegelman'] and A. D. Ebner\n",
      "https://www.researchgate.net/scientific-contributions/2145390013_A_D_Ebner\n",
      "['Rebecca'] ['Siegelman'] and Lutfi Erden\n",
      "https://www.researchgate.net/profile/Lutfi_Erden\n",
      "['R.'] ['Siegelman'] and J. A. Ritter\n",
      "https://www.researchgate.net/scientific-contributions/2145401773_J_A_Ritter\n",
      "['R.'] ['Siegelman'] and A. Moran\n",
      "https://www.researchgate.net/scientific-contributions/2145374179_A_Moran\n",
      "['R.'] ['Siegelman'] and O. Talu\n",
      "https://www.researchgate.net/scientific-contributions/2145398477_O_Talu\n",
      "['Rebecca'] ['Siegelman'] and Yi Huang\n",
      "https://www.researchgate.net/profile/Yi_Huang131\n",
      "['R.'] ['Siegelman'] and K. S. Walton\n",
      "https://www.researchgate.net/scientific-contributions/2145401594_K_S_Walton\n",
      "['Rebecca'] ['Siegelman'] and Pierre Billemont\n",
      "https://www.researchgate.net/profile/Pierre_Billemont\n",
      "['Rebecca'] ['Siegelman'] and Guy De Weireld\n",
      "https://www.researchgate.net/profile/Guy_De_Weireld\n"
     ]
    }
   ],
   "source": [
    "# Testing Rebecca Siegelman (scientific-contributions case)\n",
    "\n",
    "driver = obtain_driver(\"https://www.researchgate.net/search\")\n",
    "time.sleep(1)\n",
    "\n",
    "author = \"0000-0002-4249-6118\"\n",
    "\n",
    "soup_it(show_authors(search_paper(\"10.1007/s10450-018-9958-x\", driver)), authors_ids[author], authors_urls, author)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "*****2019-06-25 13:13:30.508967*****\n",
      "\n",
      "Checking for linux64 geckodriver:v0.24.0 in cache\n",
      "Driver found in /home/local/NIST/jfl2/.wdm/geckodriver/v0.24.0/linux64/geckodriver\n",
      "\n",
      "---New search 2019-06-25 13:13:42.081979---\n",
      "DOI: 10.1039/B822834e\n",
      "Success\n",
      "DONE - 0.0194244384765625\n",
      "['Francois'] ['Henn'] and Sabine Devautour-Vinot\n",
      "https://www.researchgate.net/scientific-contributions/35338587_Sabine_Devautour-Vinot\n",
      "['Francois'] ['Henn'] and Guillaume Maurin\n",
      "https://www.researchgate.net/profile/Guillaume_Maurin\n",
      "['Francois'] ['Henn'] and Francois Henn\n",
      "https://www.researchgate.net/profile/Francois_Henn <-------------\n",
      "['Francois'] ['Henn'] and Christian Serre\n",
      "https://www.researchgate.net/profile/Christian_Serre\n",
      "['Francois'] ['Henn'] and Thomas Devic\n",
      "https://www.researchgate.net/scientific-contributions/39843151_Thomas_Devic\n",
      "['François'] ['Henn'] and Gérard Férey\n",
      "https://www.researchgate.net/profile/Gerard_Ferey\n"
     ]
    }
   ],
   "source": [
    "# Testing Francois (special character in database but not on researchgate)\n",
    "\n",
    "driver = obtain_driver(\"https://www.researchgate.net/search\")\n",
    "time.sleep(1)\n",
    "\n",
    "author = \"00825555e861a984384ccc94310829a3ff525a07\"\n",
    "\n",
    "soup_it(show_authors(search_paper(\"10.1039/B822834e\", driver)), authors_ids[author], authors_urls, author)\n",
    "\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "\n",
    "for author in sorted(authors_urls)[:4]:\n",
    "    print(author)\n",
    "    print(authors_urls[author])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(authors_urls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(authors_ids[\"040cebbec1f902a6fa063eef81989e4a82ce7515\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing cell\n",
    "\n",
    "overall_first_time = time.time()\n",
    "\n",
    "driver = obtain_driver(\"https://www.researchgate.net/search\")\n",
    "time.sleep(1)\n",
    "\n",
    "\n",
    "# doi_list = [\"10.1021/acs.iecr.5b03509\", \"10.1007/s10450-014-9639-3\", \"10.1002/adfm.200500563\", \"10.1002/adfm.200500561\", \"10.1002/adfm.200500563\"]\n",
    "# source = search_paper(\"10.1021/acs.iecr.5b03509\", driver)   # 6 authors\n",
    "# source = search_paper(\"10.1007/s10450-014-9639-3\", driver)  # 9 authors\n",
    "# source = search_paper(\"10.1002/adfm.200500561\", driver)     # 4 authors\n",
    "# source = search_paper(\"10.1002/adfm.200500563\")     # doesn't exist\n",
    "doi_list = ['10.1016/j.carbon.2009.06.046', '10.1016/j.coal.2004.05.002', '10.1016/j.coal.2005.07.003', '10.1016/j.coal.2007.01.005', '10.1016/j.coal.2010.08.013', '10.1016/s0166-5162(02)00078-2', '10.1016/s0375-6742(03)00122-5']\n",
    "\n",
    "for doi in doi_list:\n",
    "    soup_it(show_authors(search_paper(doi, driver)), \"Gensterblum\")\n",
    "    time.sleep(.8)\n",
    "\n",
    "driver.quit()\n",
    "\n",
    "final_time = time.time() - overall_first_time\n",
    "print(final_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
