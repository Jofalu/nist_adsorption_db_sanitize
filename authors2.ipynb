{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # used for managing the JSON files from API\n",
    "from urllib.request import urlopen # fetch URl of API\n",
    "from pprint import pprint # just for printing values for human use\n",
    "from collections import Counter # used for determining duplicate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the API calls, only need to do this once per run session\n",
    "\n",
    "# Loads the authors (and their IDs) to json\n",
    "authors = json.load(urlopen(\"http://dirac.nist.gov/adsorption.nist.gov/isodb/api/authors.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0000-0002-6496-8411\n",
      "0000-0002-2005-3877\n",
      "0000-0001-6682-3040\n",
      "0000-0001-8081-8723\n",
      "0000-0001-5192-0016\n",
      "0000-0002-0197-833X\n",
      "0000-0003-1770-412X\n",
      "0000-0002-4907-7418\n",
      "0000-0003-4843-8776\n",
      "0000-0002-0583-6435\n",
      "0000-0002-1328-7376\n",
      "0000-0003-0931-085X\n",
      "0000-0001-5404-4728\n",
      "0000-0003-4838-5678\n",
      "0000-0002-7412-428X\n",
      "0000-0003-0345-2697\n",
      "0000-0001-7998-4492\n",
      "0000-0002-2691-2986\n",
      "0000-0001-8576-1914\n",
      "0000-0003-0860-5488\n",
      "0000-0002-2816-2875\n",
      "0000-0002-1894-366X\n",
      "0000-0002-5013-1194\n",
      "0000-0002-6845-4354\n",
      "0000-0002-9523-6918\n",
      "0000-0001-6082-5862\n",
      "0000-0002-9664-3697\n",
      "0000-0001-8224-839X\n",
      "0000-0001-8155-6489\n",
      "0000-0002-3608-8003\n",
      "0000-0001-6501-8875\n",
      "0000-0002-7660-6768\n",
      "0000-0001-9627-2331\n",
      "0000-0001-9555-6009\n",
      "0000-0001-7586-9841\n",
      "0000-0001-7792-4322\n",
      "0000-0002-5115-1488\n",
      "0000-0001-5905-8336\n",
      "0000-0002-9359-9889\n",
      "0000-0003-1288-5451\n",
      "0000-0001-8379-2098\n",
      "0000-0002-0528-9814\n",
      "0000-0003-2749-4269\n",
      "0000-0003-4757-4741\n",
      "0000-0002-2980-7997\n",
      "0000-0002-4662-8448\n",
      "0000-0002-0284-7147\n",
      "0000-0003-0967-6560\n",
      "0000-0002-6018-3641\n",
      "0000-0002-6260-7727\n",
      "0000-0002-4249-6118\n",
      "0000-0002-6122-5786\n",
      "0000-0002-8098-9175\n",
      "0000-0001-7141-1489\n",
      "0000-0001-8562-723X\n",
      "0000-0001-7436-6273\n",
      "0000-0003-4627-072X\n",
      "0000-0002-8485-5676\n",
      "0000-0003-1117-4017\n",
      "0000-0002-7378-100X\n",
      "0000-0003-1997-991X\n",
      "0000-0003-4798-3641\n",
      "0000-0002-4427-2150\n",
      "0000-0002-5237-1255\n"
     ]
    }
   ],
   "source": [
    "for person in authors:\n",
    "    if person[\"orc_id\"] != \"\":\n",
    "        print(person[\"orc_id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads API call for papers\n",
    "papers = json.load(urlopen(\"http://dirac.nist.gov/adsorption.nist.gov/isodb/api/minimalbiblio.json\"))\n",
    "\n",
    "# Writes to file \n",
    "with open(\"./stored_authors/papers.txt\", \"w\") as papers_file:\n",
    "    pprint(papers, stream = papers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes to a file ID name pairings so other scripts won't have to load the authors.json file. \n",
    "# Also provides a method to access names from an author_id\n",
    "\n",
    "authors_ids = {}\n",
    "\n",
    "for person in authors:\n",
    "    authors_ids[person[\"author_id\"]] = [person[\"given_name\"], person[\"middle_name\"], person[\"family_name\"]]\n",
    "\n",
    "with open(\"./stored_authors/authors_ids.txt\", \"w\") as ids_file:\n",
    "    pprint(authors_ids, stream = ids_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a dictionary of authors last names and their associated first names\n",
    "\n",
    "authors_names = {}\n",
    "\n",
    "for person in authors:\n",
    "    if person[\"given_name\"]:\n",
    "        first_name = person[\"given_name\"]\n",
    "    else: \n",
    "        first_name = \"\"\n",
    "        \n",
    "    id = person[\"author_id\"]\n",
    "    last_name = person[\"family_name\"]\n",
    "    \n",
    "    if last_name not in authors_names.keys():\n",
    "        authors_names[last_name] = [ (first_name, id) ]\n",
    "    else:\n",
    "        authors_names[last_name].append( (first_name, id) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sorts the names to place similar/same names closer to each other. The purpose is just for human viewing \n",
    "# and all lists deriving from this one will also be sorted\n",
    "\n",
    "for last_name, first_name in authors_names.items():\n",
    "    first_name.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a dictionary of authors whose first names are just initials or contain no first name at akk\n",
    "\n",
    "unknown_authors = {}\n",
    "matchless_authors = []\n",
    "\n",
    "for last_name, first_names in authors_names.items():          # Iterates through last names\n",
    "    for person in first_names:                                # Iterates through first names\n",
    "        if (\".\" in person[0] and len(person[0]) <= 2) or person[0] == \"\": # Checks if first name initial only or empty\n",
    "            unknown_authors[ person[1] ] = []                 # Initializes the list associated with unknown person's id\n",
    "\n",
    "# As of 2019/06/05, there are 6 people without first names\n",
    "\n",
    "\n",
    "# Pairs the unknown authors with possible matches\n",
    "for unknown, matches in unknown_authors.items():\n",
    "    for person in authors_names[authors_ids[unknown][2]]:\n",
    "        # Case of empty first name unknown, anyone could match\n",
    "        if authors_ids[unknown][0] == \"\" and person[1] != unknown: \n",
    "            matches.append( person[1] )\n",
    "            \n",
    "        # Only matches with same first letter\n",
    "        elif authors_ids[unknown][0] != \"\" and person[1] != unknown and person[0][0] == authors_ids[unknown][0][0]: \n",
    "            matches.append( person[1] )\n",
    "    if not matches: # If the author has no matches, they're unique, this list is to pop them later\n",
    "        matchless_authors.append(unknown)\n",
    "\n",
    "# Write all of the unknowns, even with no matches to a file\n",
    "with open(\"./stored_authors/all_unknown_authors.txt\", \"w\") as unknowns_file:\n",
    "    pprint(unknown_authors, stream = unknowns_file)\n",
    "     \n",
    "# Remove matchless authors from the dictionary since they are unique\n",
    "for author in matchless_authors:\n",
    "    unknown_authors.pop(author)\n",
    "\n",
    "# This finishes the processing for unknown authors (first initial only or no first name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding duplicate names\n",
    "\n",
    "duplicate_authors = {}\n",
    "\n",
    "# Iterates through all authors last names\n",
    "for last_name, first_names in authors_names.items():\n",
    "    if len(first_names) > 1: # eliminates last names with only one associated person\n",
    "        temp_list = []       # temporary list for names to count with Counter\n",
    "        for person in first_names:\n",
    "            if len(person[0]) >= 2 and \".\" not in person[0] and person[0] != \"\": # Ignores unknown names, covered by other case\n",
    "                temp_list.append(person[0])\n",
    "        temp_counter = Counter(temp_list) # Counters instances of first names\n",
    "        for first_name, freq in temp_counter.items():\n",
    "            if freq > 1:\n",
    "                duplicate_authors[ (first_name, last_name) ] = [] # Append to list of duplicates \n",
    "                \n",
    "        for duplicate, ids in duplicate_authors.items(): # Adds author_ids to the duplicate list \n",
    "            for person in first_names:\n",
    "                if person[0] == duplicate[0] and last_name == duplicate[1]: # Need to check last name as well as duplicates dict contains all duplicates, not just specific to this iteration\n",
    "                    ids.append(person[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing all of the unknown authors to file\n",
    "\n",
    "with open(\"./stored_authors/unknown_authors.txt\", \"w\") as unknowns_file:\n",
    "    pprint(unknown_authors, stream = unknowns_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing all of the duplicate authors to file\n",
    "\n",
    "with open(\"./stored_authors/duplicate_authors.txt\", \"w\") as duplicates_file:\n",
    "    pprint(duplicate_authors, stream = duplicates_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concludes processing for identifying unknown and duplicate authors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
