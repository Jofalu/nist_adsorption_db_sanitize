{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # used for managing the JSON files from API\n",
    "from urllib.request import urlopen # fetch URl of API\n",
    "from pprint import pprint # just for printing values for human use\n",
    "from collections import Counter # used for determining duplicate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the API calls, only need to do this once per run session\n",
    "\n",
    "# Loads the authors (and their IDs) to json\n",
    "authors = json.load(urlopen(\"http://dirac.nist.gov/adsorption.nist.gov/isodb/api/authors.json\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './stored_authors/authors_ids.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-9197339fd954>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mauthors_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mperson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"author_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mperson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"given_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"middle_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mperson\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"family_name\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./stored_authors/authors_ids.txt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mids_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mauthors_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './stored_authors/authors_ids.txt'"
     ]
    }
   ],
   "source": [
    "# Writes to a file ID name pairings so other scripts won't have to load the authors.json file\n",
    "\n",
    "authors_ids = {}\n",
    "\n",
    "for person in authors:\n",
    "    authors_ids[person[\"author_id\"]] = [person[\"given_name\"], person[\"middle_name\"], person[\"family_name\"]]\n",
    "\n",
    "with open(\"./stored_authors/authors_ids.txt\", \"w\") as ids_file:\n",
    "    pprint(authors_ids, stream = ids_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a dictionary of authors last names and their associated first names\n",
    "\n",
    "authors_names = {}\n",
    "\n",
    "for person in authors:\n",
    "    if person[\"given_name\"]:\n",
    "        first_name = person[\"given_name\"]\n",
    "    else: \n",
    "        first_name = \"\"\n",
    "        \n",
    "    id = person[\"author_id\"]\n",
    "    last_name = person[\"family_name\"]\n",
    "    \n",
    "    if last_name not in authors_names.keys():\n",
    "        authors_names[last_name] = [ (first_name, id) ]\n",
    "    else:\n",
    "        authors_names[last_name].append( (first_name, id) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sorts the names to place similar/same names closer to each other. The purpose is just for human viewing \n",
    "# and all lists deriving from this one will also be sorted\n",
    "\n",
    "for last_name, first_name in authors_names.items():\n",
    "    first_name.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a dictionary of authors whose first names are just initials or contain no first name at akk\n",
    "\n",
    "unknown_authors = {}\n",
    "matchless_authors = []\n",
    "\n",
    "for last_name, first_names in authors_names.items():          # Iterates through last names\n",
    "    for person in first_names:                                # Iterates through first names\n",
    "        if (\".\" in person[0] and len(person[0]) <= 2) or person[0] == \"\": # Checks if first name initial only or empty\n",
    "            unknown_authors[ (last_name, person) ] = []       # Initializes the list associated with unknown\n",
    "\n",
    "# As of 2019/06/05, there are 6 people without first names\n",
    "\n",
    "\n",
    "# Pairs the unknown authors with possible matches\n",
    "for unknown, matches in unknown_authors.items():\n",
    "    for person in authors_names[unknown[0]]:\n",
    "        # Case of empty first name unknown, anyone could match\n",
    "        if unknown[1][0] == \"\" and person[1] != unknown[1][1]: \n",
    "            matches.append( [person[0], person[1]] )\n",
    "            \n",
    "        # Only matches with same first letter\n",
    "        elif unknown[1][0] != \"\" and person[1] != unknown[1][1] and person[0][0] == unknown[1][0][0]: \n",
    "            matches.append( [person[0], person[1]] )\n",
    "    if not matches: # If the author has no matches, they're unique, this list is to pop them later\n",
    "        matchless_authors.append(unknown)\n",
    "\n",
    "# Write all of the unknowns, even with no matches to a file\n",
    "with open(\"./stored_authors/all_unknown_authors.txt\", \"w\") as unknowns_file:\n",
    "    pprint(unknown_authors, stream = unknowns_file)\n",
    "     \n",
    "# Remove matchless authors from the dictionary since they are unique\n",
    "for author in matchless_authors:\n",
    "    unknown_authors.pop(author)\n",
    "\n",
    "# This finishes the processing for unknown authors (first initial only or no first name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding duplicate names\n",
    "\n",
    "duplicate_author_names = []\n",
    "\n",
    "# Iterates through all authors last names\n",
    "for last_name, first_names in authors_names.items():\n",
    "    if len(first_names) > 1: # eliminates last names with only one associated person\n",
    "        temp_list = []       # temporary list for names to count with Counter\n",
    "        for person in first_names:\n",
    "            if (len(person[0]) >= 2 and \".\" not in person[0] and person[0] != \"\"): # Ignores unknown names, covered by other case\n",
    "                temp_list.append(person[0])\n",
    "        temp_counter = Counter(temp_list) # Counters instances of first names\n",
    "        for first_name, freq in temp_counter.items():\n",
    "            if (freq > 1):\n",
    "                duplicate_author_names.append( [first_name, last_name] ) # Append to list of duplicates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prints all authors\n",
    "\n",
    "# pprint(authors_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing matches for authors with no first name\n",
    "\n",
    "# for unknown, matches in unknown_authors.items():\n",
    "#     if unknown[1][0] == \"\":\n",
    "#         print(unknown[0])\n",
    "#         pprint(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing possible matches with authors who had first initials\n",
    "\n",
    "# for unknown, matches in unknown_authors.items():\n",
    "#     if unknown[1][0] != \"\" and matches:\n",
    "#         print(unknown[1][0] + \" \" + unknown[0] + \" \" + unknown[1][1])\n",
    "#         pprint(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Printing an example of duplicate_author_names\n",
    "\n",
    "pprint(duplicate_author_names[:4])\n",
    "# pprint(duplicate_author_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing all of the unknown authors to file\n",
    "\n",
    "with open(\"./stored_authors/unknown_authors.txt\", \"w\") as unknowns_file:\n",
    "    pprint(unknown_authors, stream = unknowns_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing all of the duplicate authors to file\n",
    "\n",
    "with open(\"./stored_authors/duplicate_authors.txt\", \"w\") as duplicates_file:\n",
    "    pprint(duplicate_author_names, stream = duplicates_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concludes processing for identifying unknown and duplicate authors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
