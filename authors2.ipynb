{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json # used for managing the JSON files from API\n",
    "from urllib.request import urlopen # fetch URl of API\n",
    "from pprint import pprint # just for printing values for human use\n",
    "from collections import Counter # used for determining duplicate names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the API calls, only need to do this once per run session\n",
    "\n",
    "# Loads the authors (and their IDs) to json\n",
    "# authors = json.load(urlopen(\"http://dirac.nist.gov/adsorption.nist.gov/isodb/api/authors.json\"))\n",
    "authors = json.load(urlopen(\"http://pn108747.nist.gov:3680/adsorption.nist.gov/isodb/api/authors.json\"))\n",
    "\n",
    "# Loads API call for papers\n",
    "# papers = json.load(urlopen(\"http://dirac.nist.gov/adsorption.nist.gov/isodb/api/minimalbiblio.json\"))\n",
    "papers = json.load(urlopen(\"http://pn108747.nist.gov:3680/adsorption.nist.gov/isodb/api/minimalbiblio.json\"))\n",
    "# Writes to file \n",
    "with open(\"./stored_authors/papers.txt\", \"w\") as papers_file:\n",
    "    pprint(papers, stream = papers_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writes to a file ID name pairings so other scripts won't have to load the authors.json file. \n",
    "# Also provides a method to access names from an author_id\n",
    "\n",
    "authors_ids = {}\n",
    "\n",
    "for person in authors:\n",
    "    authors_ids[person[\"author_id\"]] = [person[\"given_name\"], person[\"middle_name\"], person[\"family_name\"]]\n",
    "\n",
    "with open(\"./stored_authors/authors_ids.txt\", \"w\") as ids_file:\n",
    "    pprint(authors_ids, stream = ids_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a dictionary of authors last names and their associated first names\n",
    "\n",
    "authors_names = {}\n",
    "\n",
    "for person in authors:\n",
    "    if person[\"given_name\"]:\n",
    "        first_name = person[\"given_name\"]\n",
    "    else: \n",
    "        first_name = \"\"\n",
    "        \n",
    "    id = person[\"author_id\"]\n",
    "    last_name = person[\"family_name\"]\n",
    "    \n",
    "    if last_name not in authors_names.keys():\n",
    "        authors_names[last_name] = [ (first_name, id) ]\n",
    "    else:\n",
    "        authors_names[last_name].append( (first_name, id) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Sorts the names to place similar/same names closer to each other. The purpose is just for human viewing \n",
    "# and all lists deriving from this one will also be sorted\n",
    "\n",
    "for last_name, first_name in authors_names.items():\n",
    "    first_name.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generates a dictionary of authors whose first names are just initials or contain no first name at akk\n",
    "\n",
    "unknown_authors = {}\n",
    "matchless_authors = []\n",
    "\n",
    "for last_name, first_names in authors_names.items():          # Iterates through last names\n",
    "    for person in first_names:                                # Iterates through first names\n",
    "        if (\".\" in person[0] and len(person[0]) <= 2) or person[0] == \"\": # Checks if first name initial only or empty\n",
    "            unknown_authors[ person[1] ] = []                 # Initializes the list associated with unknown person's id\n",
    "\n",
    "# As of 2019/06/05, there are 6 people without first names\n",
    "\n",
    "\n",
    "# Pairs the unknown authors with possible matches\n",
    "for unknown, matches in unknown_authors.items():\n",
    "    for person in authors_names[authors_ids[unknown][2]]:\n",
    "        # Case of empty first name unknown, anyone could match\n",
    "        if authors_ids[unknown][0] == \"\" and person[1] != unknown: \n",
    "            matches.append( person[1] )\n",
    "            \n",
    "        # Only matches with same first letter\n",
    "        elif authors_ids[unknown][0] != \"\" and person[1] != unknown and person[0][0] == authors_ids[unknown][0][0]: \n",
    "            matches.append( person[1] )\n",
    "    if not matches: # If the author has no matches, they're unique, this list is to pop them later\n",
    "        matchless_authors.append(unknown)\n",
    "\n",
    "# Write all of the unknowns, even with no matches to a file\n",
    "with open(\"./stored_authors/all_unknown_authors.txt\", \"w\") as unknowns_file:\n",
    "    pprint(unknown_authors, stream = unknowns_file)\n",
    "     \n",
    "# Remove matchless authors from the dictionary since they are unique\n",
    "for author in matchless_authors:\n",
    "    unknown_authors.pop(author)\n",
    "\n",
    "# This finishes the processing for unknown authors (first initial only or no first name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finding duplicate names\n",
    "\n",
    "duplicate_authors = {}\n",
    "\n",
    "# Iterates through all authors last names\n",
    "for last_name, first_names in authors_names.items():\n",
    "    if len(first_names) > 1: # eliminates last names with only one associated person\n",
    "        temp_list = []       # temporary list for names to count with Counter\n",
    "        for person in first_names:\n",
    "            if len(person[0]) >= 2 and \".\" not in person[0] and person[0] != \"\": # Ignores unknown names, covered by other case\n",
    "                temp_list.append(person[0])\n",
    "        temp_counter = Counter(temp_list) # Counters instances of first names\n",
    "        for first_name, freq in temp_counter.items():\n",
    "            if freq > 1:\n",
    "                duplicate_authors[ (first_name, last_name) ] = [] # Append to list of duplicates \n",
    "                \n",
    "        for duplicate, ids in duplicate_authors.items(): # Adds author_ids to the duplicate list \n",
    "            for person in first_names:\n",
    "                if person[0] == duplicate[0] and last_name == duplicate[1]: # Need to check last name as well as duplicates dict contains all duplicates, not just specific to this iteration\n",
    "                    ids.append(person[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing all of the unknown authors to file\n",
    "\n",
    "with open(\"./stored_authors/unknown_authors.txt\", \"w\") as unknowns_file:\n",
    "    pprint(unknown_authors, stream = unknowns_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Writing all of the duplicate authors to file\n",
    "\n",
    "with open(\"./stored_authors/duplicate_authors.txt\", \"w\") as duplicates_file:\n",
    "    pprint(duplicate_authors, stream = duplicates_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Concludes processing for identifying unknown and duplicate authors."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
